{
    "documentation": [
        "1. OOMKilled Pod Status \n A container is terminated and marked OOMKilled if it tries to use more memory than its limit. Kubernetes enforces these limits via the container runtime and the Linux kernel's OOM killer.",
        "2. Resource Limits in Pods \n You can specify memory and CPU limits in a Pod specification. The memory limit is enforced strictly: if a container exceeds it, it is killed.",
        "3. Configuring Node.js Memory via Environment Variables \n For Node.js applications, you can pass options like --max-old-space-size via the NODE_OPTIONS environment variable to raise or lower heap memory allocation.",
        "4. Container Exit Code 137\n Exit code 137 indicates that the container was terminated by the kernel due to an out-of-memory condition (SIGKILL).",
        "5. Monitoring Resource Usage with Metrics Server\n You can use the Kubernetes Metrics Server or other tools to inspect the actual memory usage of running containers before setting limits."
    ],

    "solution": [
        "1. Analyze Current Memory Limits\n\nCheck the memory limit set for your container:\n\nresources:\n  limits:\n    memory: \"512Mi\"\nIf not specified, set it explicitly.",
        "2. Raise Memory Limit or Optimize Node Heap Settings\n\nIncrease the memory allocation either in Kubernetes limits or via NODE_OPTIONS:\n\nOption 1: Raise container memory limit (recommended)\n\nresources:\n  limits:\n    memory: \"1024Mi\"  # Adjust as needed based on monitoring\nOption 2: Adjust Node.js memory usage\n\nUpdate the environment variable in your pod spec:\n\nenv:\n- name: NODE_OPTIONS\n  value: \"--max-old-space-size=768\"",
        "3. Monitor Actual Memory Usage\n\nUse Metrics Server to validate how much memory your app uses in practice:\n\nkubectl top pod <your-pod-name>\nIf usage consistently nears or exceeds limits, raise the memory cap.",
        "4. Add Readiness Probe Delay (Optional)\n\nIf the container crashes during init, give it more time:\n\nreadinessProbe:\n  httpGet:\n    path: /health\n    port: 8080\n  initialDelaySeconds: 20\n  timeoutSeconds: 3",
        "5. Apply and Verify\n\nRedeploy the workload:\n\nkubectl apply -f deployment.yaml\nkubectl get pods -w\nCheck if pod status stabilizes and monitor for further OOM events."
    ]
}


