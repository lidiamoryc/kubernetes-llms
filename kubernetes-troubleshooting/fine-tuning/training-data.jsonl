{"prompt": "**Diagnostic Evidence**:\n- Critical Logs: Connection refused to DB_HOST=10.0.0.5\nDatabase unreachable - exiting\n- Cluster Events: Connection refused to DB_HOST=10.0.0.5\n- Environment Variables: {\"DB_HOST\": \"10.0.0.5\", \"DB_PORT\": \"5432\"}\n- Probe Warning: Probe timeout might be too short", "completion": " 1. Service Discovery & DNS\n\"Pods should reference Services by their DNS name (<service>.<namespace>.svc.cluster.local), not static IPs.\"\n\n2. CrashLoopBackOff Definition\n\"A pod enters CrashLoopBackOff when it crashes repeatedly. Check with kubectl logs --previous.\"\n\n3. Readiness Probe Best Practices\n\"Set initialDelaySeconds longer than max init time. timeoutSeconds should exceed processing time.\""}
{"prompt": "**Diagnostic Evidence**:\n- Critical Logs: Error response from daemon: pull access denied for my-registry/app:v1.3\n- Cluster Events: Failed to pull image \"my-registry/app:v1.3\"\n- Environment Variables: {\"REGISTRY_CRED\": \"*****\"}\n- Probe Warning: ", "completion": "1. ImagePullBackOff Definition\n\"ImagePullBackOff means Kubernetes cannot pull a container image. This might be due to invalid image name or lack of permissions.\"\n\n2. imagePullSecrets for Private Registries\n\"To pull from a private registry, define imagePullSecrets in the pod spec. Secrets must be in the same namespace.\"\n\n3. imagePullPolicy Behavior\n\"Set imagePullPolicy to Always to ensure a fresh image pull. Default policy depends on tag used.\""}]}
{"prompt": "**Diagnostic Evidence**:\n- Critical Logs: FATAL ERROR: JS heap out of memory\n- Cluster Events: Container exited with code 137\n- Environment Variables: {\"NODE_OPTIONS\": \"--max-old-space-size=512\"}\n- Probe Warning: ", "completion": "1. OOMKilled Container Status\n\"Exit code 137 typically means the container was terminated due to memory limits (OOMKilled).\"\n\n2. Memory Resource Management\n\"Use 'resources.limits.memory' to constrain memory usage. Adjust based on application requirements.\"\n\n3. NODE_OPTIONS Usage in Node.js\n\"NODE_OPTIONS can be used to control V8 memory behavior. Ensure it's compatible with container memory limits.\""}
{"prompt": "**Diagnostic Evidence**:\n- Critical Logs: Error: ENOENT: no such file or directory, open '/app/config.json'\n- Cluster Events: configmap 'web-app-config' not found\n- Environment Variables: {}\n- Probe Warning: ", "completion": "1. ConfigMap Volume Mounting\n\"If a ConfigMap is referenced in a pod spec but does not exist, the volume will fail to mount.\"\n\n2. Using subPath in Volume Mounts\n\"Using subPath allows mounting a single file from a ConfigMap. Ensure the file key exists in the ConfigMap.\"\n\n3. ConfigMap Lifecycle\n\"Changes to a ConfigMap will not reflect automatically in pods using subPath. Restart required.\""}
{"prompt": "**Diagnostic Evidence**:\n- Critical Logs: Readiness probe failed: HTTP probe failed with status code: 404\n- Cluster Events: Container myapp not ready\n- Environment Variables: {}\n- Probe Warning: path: /healthz, port: 8080, initialDelaySeconds: 3", "completion": "1. Readiness Probe Failures\n\"If a readiness probe fails, the container is marked as not ready and removed from service endpoints.\"\n\n2. HTTP Probes\n\"Readiness probes using HTTP should return 2xx or 3xx to be considered successful. 404 indicates failure.\"\n\n3. Troubleshooting Readiness Probes\n\"Verify path and port match your container's actual health endpoint. Use kubectl exec to test.\""}
{"prompt": "**Diagnostic Evidence**:\n- Critical Logs: CrashLoopBackOff: Application crashes immediately after start\n- Cluster Events: Back-off restarting failed container\n- Environment Variables: {}\n- Probe Warning: ", "completion": "1. CrashLoopBackOff Definition\n\"A pod enters CrashLoopBackOff when it repeatedly crashes. The kubelet backs off on restart attempts.\"\n\n2. Using kubectl logs\n\"Use kubectl logs --previous to inspect the last run of a crashing container.\"\n\n3. Lifecycle and Probes\n\"Consider startup probes if your application takes a long time to initialize, to prevent premature failure detection.\""}
{"prompt": "**Diagnostic Evidence**:\n- Critical Logs: VolumeMount error: mount target does not exist\n- Cluster Events: Failed to mount volume 'data-vol' to path '/data' - no such file or directory\n- Environment Variables: {}\n- Probe Warning: ", "completion": "1. Volume Mount Paths\n\"Ensure the path specified in the volumeMount exists inside the container. Kubernetes will not create missing target directories.\"\n\n2. Pod Volume Configuration\n\"Check that the volumeMount path and name match the declared volumes in the pod spec.\"\n\n3. Filesystem Permissions\n\"Mounts may fail if directory permissions prevent Kubernetes from accessing the target path.\""}
{"prompt": "**Diagnostic Evidence**:\n- Critical Logs: Container is running but application is unreachable\n- Cluster Events: Service has no endpoints\n- Environment Variables: {}\n- Probe Warning: ", "completion": "1. Services and Endpoints\n\"If a Service shows no endpoints, it means no pods match the Service selector.\"\n\n2. Label Selectors in Services\n\"Verify that the selector in the Service matches the labels on the Pods you intend to expose.\"\n\n3. Debugging Service-to-Pod Mapping\n\"Use 'kubectl get endpoints <service>' to see which pods are selected by the service.\""}
{"prompt": "**Diagnostic Evidence**:\n- Critical Logs: Liveness probe failed: timeout\n- Cluster Events: Container killed and restarted due to failed probe\n- Environment Variables: {}\n- Probe Warning: Liveness probe using HTTP GET to /health", "completion": "1. Liveness Probe Timeout\n\"A failed liveness probe indicates the container is unhealthy. Kubernetes will restart it automatically.\"\n\n2. Probe Configuration\n\"Ensure that the liveness probe's timeoutSeconds value is sufficient for your application response time.\"\n\n3. HTTP Probe Details\n\"An HTTP GET probe expects a 2xx or 3xx status code. Anything else results in failure.\""}
{"prompt": "**Diagnostic Evidence**:\n- Critical Logs: Permission denied when writing to /var/data\n- Cluster Events: Pod unable to write to mounted volume\n- Environment Variables: {}\n- Probe Warning: ", "completion": "1. Volume Permissions\n\"Ensure the container's user has appropriate write permissions on the mounted volume.\"\n\n2. Security Contexts\n\"Use securityContext to set runAsUser and fsGroup to control file permissions in shared volumes.\"\n\n3. HostPath Volume Considerations\n\"When using hostPath volumes, verify that the host path exists and is accessible by the container runtime.\""}
{"prompt": "**Diagnostic Evidence**:\n- Critical Logs: CrashLoopBackOff with Java OutOfMemoryError\n- Cluster Events: Container restarted repeatedly\n- Environment Variables: {\"JAVA_OPTS\": \"-Xmx256m\"}\n- Probe Warning: ", "completion": "1. Java Memory Settings\n\"The -Xmx option sets the maximum heap size for the JVM. Ensure it fits within the container's memory limit.\"\n\n2. CrashLoopBackOff Explanation\n\"CrashLoopBackOff means the pod is crashing on start. Kubernetes retries with increasing delay.\"\n\n3. Memory Limits and Requests\n\"Memory requests and limits define how much memory a pod can use. Set limits to avoid OOM kills.\""}
